"""
Alerting System + API

Stores and manages alerts generated by the API degradation detection pipeline.
Provides persistence and retrieval of alerts with full context and explanations.
Includes REST API endpoints for alert retrieval.

This is the final component that makes the system real - without alert output,
the system effectively doesn't exist for users.
"""

from typing import Dict, Any, List, Optional
import os
import json
import sqlite3
from datetime import datetime, timezone
import uuid
import time
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware

# Legacy imports for backward compatibility
SLACK_WEBHOOK = os.environ.get('SLACK_WEBHOOK_URL')

BASE_DIR = os.path.dirname(__file__)
DATA_DIR = os.path.abspath(os.path.join(BASE_DIR, '..', 'data'))
ALERTS_DB = os.path.join(DATA_DIR, 'alerts.db')
ALERTS_FILE = os.path.join(DATA_DIR, 'alerts.jsonl')  # Legacy support


class AlertStore:
    """Persistent storage for alerts with SQLite backend."""

    def __init__(self):
        os.makedirs(DATA_DIR, exist_ok=True)
        self._init_db()

    def _init_db(self):
        """Initialize the alerts database."""
        conn = sqlite3.connect(ALERTS_DB)
        cursor = conn.cursor()

        cursor.execute('''
            CREATE TABLE IF NOT EXISTS alerts (
                id TEXT PRIMARY KEY,
                endpoint TEXT NOT NULL,
                severity TEXT NOT NULL,
                window TEXT NOT NULL,
                anomaly_count INTEGER NOT NULL,
                avg_deviation REAL NOT NULL,
                max_deviation REAL NOT NULL,
                anomalous_metrics TEXT NOT NULL,  -- JSON array
                explanation TEXT NOT NULL,
                insights TEXT NOT NULL,  -- JSON array
                recommendations TEXT NOT NULL,  -- JSON array
                timestamp TEXT NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'active'  -- active, acknowledged, resolved
            )
        ''')

        conn.commit()
        conn.close()

    def store_alert(self, alert: Dict[str, Any]) -> str:
        """
        Store an explained alert and return its ID.

        Alert must contain: endpoint, severity, window, anomalous_metrics,
        explanation, insights, recommendations, timestamp
        """
        alert_id = str(uuid.uuid4())

        # Prepare data for storage
        anomalous_metrics_json = json.dumps(alert['anomalous_metrics'])
        insights_json = json.dumps(alert.get('insights', []))
        recommendations_json = json.dumps(alert.get('recommendations', []))

        conn = sqlite3.connect(ALERTS_DB)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO alerts
            (id, endpoint, severity, window, anomaly_count, avg_deviation,
             max_deviation, anomalous_metrics, explanation, insights,
             recommendations, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            alert_id,
            alert['endpoint'],
            alert['severity'],
            alert['window'],
            alert.get('anomaly_count', 0),
            alert.get('avg_deviation', 0.0),
            alert.get('max_deviation', 0.0),
            anomalous_metrics_json,
            alert['explanation'],
            insights_json,
            recommendations_json,
            alert.get('timestamp', datetime.now(timezone.utc).isoformat())
        ))

        conn.commit()
        conn.close()

        return alert_id

    def get_alert(self, alert_id: str) -> Optional[Dict[str, Any]]:
        """Retrieve a specific alert by ID."""
        conn = sqlite3.connect(ALERTS_DB)
        cursor = conn.cursor()

        cursor.execute('SELECT * FROM alerts WHERE id = ?', (alert_id,))
        row = cursor.fetchone()
        conn.close()

        if not row:
            return None

        # Convert row to dict and parse JSON fields
        alert = {
            'id': row[0],
            'endpoint': row[1],
            'severity': row[2],
            'window': row[3],
            'anomaly_count': row[4],
            'avg_deviation': row[5],
            'max_deviation': row[6],
            'anomalous_metrics': json.loads(row[7]),
            'explanation': row[8],
            'insights': json.loads(row[9]),
            'recommendations': json.loads(row[10]),
            'timestamp': row[11],
            'created_at': row[12],
            'status': row[13]
        }

        return alert

    def get_all_alerts(self, limit: int = 100, status: str = None) -> List[Dict[str, Any]]:
        """Retrieve all alerts, optionally filtered by status."""
        conn = sqlite3.connect(ALERTS_DB)
        cursor = conn.cursor()

        query = 'SELECT * FROM alerts'
        params = []

        if status:
            query += ' WHERE status = ?'
            params.append(status)

        query += ' ORDER BY created_at DESC LIMIT ?'
        params.append(limit)

        cursor.execute(query, params)
        rows = cursor.fetchall()
        conn.close()

        alerts = []
        for row in rows:
            alert = {
                'id': row[0],
                'endpoint': row[1],
                'severity': row[2],
                'window': row[3],
                'anomaly_count': row[4],
                'avg_deviation': row[5],
                'max_deviation': row[6],
                'anomalous_metrics': json.loads(row[7]),
                'explanation': row[8],
                'insights': json.loads(row[9]),
                'recommendations': json.loads(row[10]),
                'timestamp': row[11],
                'created_at': row[12],
                'status': row[13]
            }
            alerts.append(alert)

        return alerts

    def update_alert_status(self, alert_id: str, status: str) -> bool:
        """Update the status of an alert (active, acknowledged, resolved)."""
        conn = sqlite3.connect(ALERTS_DB)
        cursor = conn.cursor()

        cursor.execute(
            'UPDATE alerts SET status = ? WHERE id = ?',
            (status, alert_id)
        )

        success = cursor.rowcount > 0
        conn.commit()
        conn.close()

        return success


# Global alert store instance
_alert_store = None

def get_alert_store() -> AlertStore:
    """Get the global alert store instance."""
    global _alert_store
    if _alert_store is None:
        _alert_store = AlertStore()
    return _alert_store


def store_alerts(explained_alerts: List[Dict[str, Any]]) -> List[str]:
    """
    Store multiple explained alerts and return their IDs.

    Each alert must have been processed by the explainer.
    """
    store = get_alert_store()
    alert_ids = []

    for alert in explained_alerts:
        # Ensure timestamp is set
        if 'timestamp' not in alert:
            alert['timestamp'] = datetime.now(timezone.utc).isoformat()

        alert_id = store.store_alert(alert)
        alert_ids.append(alert_id)

    return alert_ids


# Legacy functions for backward compatibility
def classify_severity(anomalies: List[Dict[str, Any]]) -> str:
    """Legacy severity classification."""
    if not anomalies:
        return 'INFO'

    num_signals = len(anomalies)
    has_high_error = any(a.get('metric') == 'error_rate' and a.get('current_value', 0) > 0.1 for a in anomalies)
    has_high_latency = any(a.get('metric') in ['avg_latency', 'p95_latency'] and abs(a.get('deviation', 0)) > 3.0 for a in anomalies)
    has_critical_severity = any(a.get('severity') == 'CRITICAL' for a in anomalies)

    if has_high_error or has_high_latency or num_signals > 3 or has_critical_severity:
        return 'CRITICAL'
    elif any(a.get('metric') in ['avg_latency', 'p95_latency'] and abs(a.get('deviation', 0)) > 2.0 for a in anomalies) or num_signals > 2:
        return 'WARN'
    else:
        return 'INFO'


def send_console(alert: Dict[str, Any]):
    """Legacy console output."""
    ts = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime())
    print('--- ALERT ---')
    print(f"time: {ts}")
    print(json.dumps(alert, indent=2))


def send_slack(alert: Dict[str, Any]):
    """Legacy Slack notification."""
    if not SLACK_WEBHOOK:
        return False
    text = f"*[{alert.get('severity','WARN')}]* {alert.get('endpoint')} - {alert.get('explanation')}"
    payload = {"text": text}
    try:
        r = httpx.post(SLACK_WEBHOOK, json=payload, timeout=5.0)
        return r.status_code == 200
    except Exception:
        return False


def alert(alert_obj: Dict[str, Any]):
    """Legacy alert function - now also stores in database."""
    # Classify severity if not set
    if 'severity' not in alert_obj:
        anomalies = alert_obj.get('anomalies', [])
        alert_obj['severity'] = classify_severity(anomalies)

    # Store in database if it has the required fields
    if all(key in alert_obj for key in ['endpoint', 'severity', 'anomalous_metrics', 'explanation']):
        try:
            store_alerts([alert_obj])
        except Exception:
            pass  # Fall back to legacy behavior

    # Legacy behavior
    send_console(alert_obj)

    # persist alert for offline analysis (legacy)
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(ALERTS_FILE, 'a', encoding='utf-8') as fh:
            fh.write(json.dumps(alert_obj) + '\n')
    except Exception:
        pass

    # try slack
    ok = send_slack(alert_obj)
    return ok


# FastAPI Application
print("DEBUG: Creating FastAPI app...")
app = FastAPI(
    title="API Degradation Detection - Alerting API",
    description="REST API for retrieving alerts from the API degradation detection system",
    version="1.0.0"
)
print("DEBUG: FastAPI app created")

# Add CORS middleware
print("DEBUG: Adding CORS middleware...")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
print("DEBUG: CORS middleware added")


# Lifecycle event hooks for better diagnostics
@app.on_event("startup")
async def _on_startup():
    print("LIFECYCLE: startup event fired")
    try:
        # Initialize alert store to ensure DB is ready at startup
        get_alert_store()
        print("LIFECYCLE: AlertStore initialized")
    except Exception as e:
        print(f"LIFECYCLE: AlertStore initialization failed: {e}")


@app.on_event("shutdown")
async def _on_shutdown():
    print("LIFECYCLE: shutdown event fired")


@app.get("/")
async def root():
    """Root endpoint - redirects to API documentation."""
    return {
        "message": "API Degradation Detection - Alerting API",
        "version": "1.0.0",
        "docs": "/docs",
        "endpoints": {
            "GET /": "API information and endpoint list",
            "GET /alerts": "Get all alerts",
            "GET /alerts/{id}": "Get specific alert",
            "PUT /alerts/{id}/status": "Update alert status",
            "GET /metrics/{endpoint}": "Get metrics for endpoint",
            "GET /health": "Health check"
        }
    }


@app.get("/alerts")
async def get_alerts(limit: int = 100, status: str = None):
    """
    Get all alerts.

    - **limit**: Maximum number of alerts to return (default: 100)
    - **status**: Filter by status (active, acknowledged, resolved)
    """
    try:
        print("DEBUG: Getting alert store...")
        store = get_alert_store()
        print("DEBUG: Fetching alerts...")
        alerts = store.get_all_alerts(limit=limit, status=status)
        print(f"DEBUG: Retrieved {len(alerts)} alerts")

        # Format alerts for API response (include required fields)
        formatted_alerts = []
        for alert in alerts:
            try:
                formatted_alert = {
                    'id': alert['id'],
                    'endpoint': alert['endpoint'],
                    'severity': alert['severity'],
                    'metrics_involved': alert['anomalous_metrics'],
                    'explanation': alert['explanation'],
                    'timestamp': alert['timestamp'],
                    'status': alert['status'],
                    'anomaly_count': alert['anomaly_count'],
                    'insights': alert['insights'],
                    'recommendations': alert['recommendations']
                }
                formatted_alerts.append(formatted_alert)
            except Exception as e:
                print(f"DEBUG: Error formatting alert {alert.get('id', 'unknown')}: {e}")
                continue

        print(f"DEBUG: Formatted {len(formatted_alerts)} alerts")
        return {"alerts": formatted_alerts, "count": len(formatted_alerts)}

    except Exception as e:
        print(f"DEBUG: Error in get_alerts: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Failed to retrieve alerts: {str(e)}")


@app.get("/alerts/{alert_id}")
async def get_alert(alert_id: str):
    """
    Get a specific alert by ID.

    - **alert_id**: The unique identifier of the alert
    """
    try:
        store = get_alert_store()
        alert = store.get_alert(alert_id)

        if not alert:
            raise HTTPException(status_code=404, detail="Alert not found")

        # Format alert for API response
        formatted_alert = {
            'id': alert['id'],
            'endpoint': alert['endpoint'],
            'severity': alert['severity'],
            'metrics_involved': alert['anomalous_metrics'],
            'explanation': alert['explanation'],
            'timestamp': alert['timestamp'],
            'status': alert['status'],
            'anomaly_count': alert['anomaly_count'],
            'insights': alert['insights'],
            'recommendations': alert['recommendations'],
            'window': alert['window'],
            'avg_deviation': alert['avg_deviation'],
            'max_deviation': alert['max_deviation'],
            'created_at': alert['created_at']
        }

        return formatted_alert

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve alert: {str(e)}")


@app.put("/alerts/{alert_id}/status")
async def update_alert_status(alert_id: str, status: str):
    """
    Update the status of an alert.

    - **alert_id**: The unique identifier of the alert
    - **status**: New status (active, acknowledged, resolved)
    """
    if status not in ['active', 'acknowledged', 'resolved']:
        raise HTTPException(status_code=400, detail="Invalid status. Must be: active, acknowledged, or resolved")

    try:
        store = get_alert_store()
        success = store.update_alert_status(alert_id, status)

        if not success:
            raise HTTPException(status_code=404, detail="Alert not found")

        return {"message": f"Alert {alert_id} status updated to {status}"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to update alert status: {str(e)}")


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {"status": "healthy", "service": "API Degradation Detection - Alerting API"}


@app.get("/metrics/{endpoint}")
async def get_metrics(endpoint: str, window: str = "15m"):
    """
    Get metrics for a specific endpoint.

    This is a mock endpoint that returns sample metrics data for demonstration.
    In a real system, this would query stored aggregated metrics.
    """
    try:
        # For now, return mock metrics data that shows degradation over time
        import random
        from datetime import datetime, timedelta

        # Generate sample metrics over the last 15 minutes
        metrics = []
        base_time = datetime.utcnow()

        for i in range(15):
            timestamp = base_time - timedelta(minutes=14-i)

            # Simulate degradation starting around minute 8
            if i < 8:
                # Normal performance
                avg_latency = 120 + random.randint(-10, 10)
                p95_latency = avg_latency * 1.5
                error_rate = 0.02 + random.uniform(-0.01, 0.01)
                request_volume = 100 + random.randint(-20, 20)
            else:
                # Degraded performance
                degradation_factor = (i - 7) / 8  # 0 to 1
                avg_latency = 120 + (800 - 120) * degradation_factor + random.randint(-20, 20)
                p95_latency = avg_latency * 1.8
                error_rate = 0.02 + (0.18 - 0.02) * degradation_factor + random.uniform(-0.02, 0.02)
                request_volume = 100 + random.randint(-30, 30)

            metrics.append({
                "window_end": timestamp.isoformat() + "Z",
                "avg_latency": round(avg_latency, 1),
                "p95_latency": round(p95_latency, 1),
                "error_rate": round(error_rate, 3),
                "request_volume": request_volume,
                "endpoint": endpoint
            })

        return metrics

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve metrics: {str(e)}")


if __name__ == '__main__':
    print('Alerting system loaded - ready to store and serve alerts!')
    print('SLACK_WEBHOOK_URL set?', bool(SLACK_WEBHOOK))
